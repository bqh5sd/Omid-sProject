#%%

import numpy as np

from sklearn.linear_model import LinearRegression
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

from sklearn.gaussian_process.kernels import RBF
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.utils import shuffle
from sklearn.preprocessing import OneHotEncoder
import pandas as pd

df_testAMP = pd.read_csv("Xiao_AMP_test.csv").copy()
df_trainAMP = pd.read_csv("Xiao_AMP_train(in).csv").copy()
df_testnonAMP = pd.read_csv("Xiao_nonAMP_test(in).csv").copy()
df_trainnonAMP = pd.read_csv("Xiao_nonAMP_train(in).csv").copy()

#concatenate the data frames
dfAMPpre = pd.concat([df_testAMP, df_trainAMP])
dfnonAMPpre = pd.concat([df_testnonAMP, df_trainnonAMP])

#Shuffle the data frames
dfAMP = shuffle(dfAMPpre)
df_nonAMP = shuffle(dfnonAMPpre)

dfpre = pd.concat([dfAMP, df_nonAMP])

#Final Data Frame
np.random.seed(1)
df = shuffle(dfpre)


activity = df["Activity"].tolist()
sequence = df["Sequence"].tolist()



def remove_numbers(sequence, unwanted_amino_acids):
    """
    Parameters
    ----------
    sequence: input the amino acid string to be processed
    unwanted_amino_acids: input the list of characters (as strings) that should be removed from the amino acid string

    Returns
    -------
    cleaned_sequence: returns an amino acid string without characters found in the unwanted_amino_acid list
    """

    cleaned_sequence = ''.join([aa for aa in sequence if aa not in unwanted_amino_acids])
    return cleaned_sequence

def one_hot_encode(amino_acid_sequence):
    """
    Parameters
    ----------
    amino_acid_sequence: This function takes one amino acid sequence input at a time and returns the 
    compatible one_hot_encoded sequence

    Returns
    -------
    merged_one_hot_encoded_sequence: this function returns not a list of separate one_hot_encoded lists,
    but a merged list with a completely one_hot_encoded amino acid sequence

    """
    # Define a list of unique amino acids
    unique_amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
    
    # Create a dictionary to map amino acids to indices
    amino_acid_to_index = {amino_acid: index for index, amino_acid in enumerate(unique_amino_acids)}
    
    one_hot_encoded_sequence = []
    unwanted_amino_acids = ['1', '2', '3', '4']
    cleaned_sequence = remove_numbers(amino_acid_sequence, unwanted_amino_acids)
    for amino_acid in cleaned_sequence:
        # Create a binary vector with all zeros
        one_hot_vector = [0] * len(unique_amino_acids)
        one_hot_vector[amino_acid_to_index[amino_acid]] = 1
        
        # Append the one-hot vector to the final sequence
        one_hot_encoded_sequence.append(one_hot_vector)
        merged_one_hot_encoded_sequence = [item for sublist in one_hot_encoded_sequence for item in sublist]
    return merged_one_hot_encoded_sequence

X =  []
lens = []
y = activity


#find the largest peptide sequence
max_len = 0
for i in range(0,len(sequence)):
    if max_len < len(one_hot_encode(sequence[i])):
        max_len = len(one_hot_encode(sequence[i]))
    lens.append(len(one_hot_encode(sequence[i])))
    X.append(one_hot_encode(sequence[i]))

X_padded = []
for xi in X:
    padded_encoded_value = np.pad(xi, (0, max_len - len(xi)), 'constant')  # Rellenar con ceros
    X_padded.append(padded_encoded_value)



""" # Convert each sublist into a concatenated string
concatenated_strings = [''.join(map(str, sublist)) for sublist in X_padded]
array = np.array(concatenated_strings)

# Convert each string into an integer
integers = [int(string) for string in concatenated_strings]
 """

# Print the result
# train linear model

#Random Forest Model
X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size = 0.2, shuffle = True) #random_state = 5

#print(X_train[0])

paramater_ranges = {"ccp_alpha": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}

#Use sklearn's GridSearchCV function to find optimal parameters
forest = RandomForestRegressor()
forest_search = GridSearchCV(forest, paramater_ranges, cv=3) 
forest_search.fit(X_train, y_train)
    
#Create a dictionary of all of the optimal parameters for the Random Forest Model
param_dict = forest_search.best_estimator_.get_params()
    
#Specify each parameter that will be used in the final Random Forest Model from the param_dict
ccp_alpha_param = param_dict["ccp_alpha"]
    
#Code the final Random Forest model with the optimized parameters from the GridSearchCV function
forest = RandomForestRegressor(n_estimators = 500, min_samples_leaf = 1, random_state = 5, ccp_alpha = ccp_alpha_param)
forest.fit(X_train, y_train)
    
#Predict test set data with optimized parameters
y_pred = forest.predict(X_test) 






#Compherhension of list







# %%
