# -*- coding: utf-8 -*-
"""
Created on Tue Jul 11 10:05:38 2023

@author: Steffanie Jones
"""
#################################### Regression Module Information ###################################
#takes an input of a fingerprint, SMILES (small molecule), or amino acid sequence (peptide) data set
#must be a CSV file with two columns (data and expected output)

#Returns General Statistics About Four Regression techniques:
    #Linear Regression
    #Gaussian Regression
    #Decision Tree
    #Random Forest Regression
#Optimizes models using GridSearchCV function (sklearn module)
#focuses on R2, MSE, MAE, and R Pearson Correlation Coefficient values as outputs 
#(to compare to other models such as neural networks)
#Current run time: ~30 minutes for a 4200-row data set
####################################################################################################
from sklearn.linear_model import LinearRegression
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

from sklearn.gaussian_process.kernels import RBF
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

import pandas as pd
import numpy as np
import time
import datetime
import sys
import matplotlib.pyplot as plt

from rdkit import Chem
from rdkit.Chem import AllChem

####################################################################################################################
#Introduction to code and user input:
print("Welcome to Regression metrics! This code will process small molecules and peptides, and")
print("therefore allow an input of a molecular fingerprint, SMILES string, or amino acid string.")
print("The code will output the performance of four regression techniques: Linear Regression,")
print("Gaussian Process Regression, Decision Tree Regression, and Random Forest Regression.") 
print("This code requires an input of a csv or txt data file composed of two columns: one column with")
print("information about the input molecule, whether it be a fingerprint, SMILES, or amino acid string,")
print("and another with the expected output value. ")
print("")
print("Please answer the following questions to customize this program for your dataset:")
print("")
data_type = input("Please input the data type. For a fingerprint data set, enter 1. For a SMILES data set, enter 2, For a amino acid/peptide data set, enter 3: ")
print("")
graph_option = input("Would you like the program to output parity plots detailing the performance of each model (Y/N)? ").lower()
print("")

####################################################################################################################
#Used to allow two types of files, txt or csv, to be inputted to the program
def txt_to_csv(input_file, output_file):
    """
    Parameters
    ----------
    input_file: input a txt file (name)
    output_file: input the name of the output file (likely the txt file's name  + "csv" instead of "txt")

    Returns
    -------
    output_file: returns the txt file as a csv so the program can process it

    """
    # Read the TXT file using pandas.
    df = pd.read_csv(input_file, sep='\t')  # You may need to adjust the separator ('\t' or ' ') based on your TXT file.
    # Save the DataFrame as a CSV file.
    df.to_csv(output_file, index=False)
    return output_file

##################################################################################################################
#Used if option 2 is chosen
def smiles_to_fingerprints(data_set, last_column):
    """

    Parameters
    ----------
    data_set: input the data csv file containing the SMILES to be converted to fingerprints.
    last_column: input the name of the data set to separate the expected results from the SMILES
    that will be converted to fingerprints.

    Returns
    -------
    X_data : the newly converted fingerprint datasets returned to be used in the regression models.
    y_data : the separated "expected" data values returned to be used in the regression models.

    """
    df = pd.read_csv(data_set, delimiter=",")

    smiles_dataset = df.drop(last_column, axis=1)
    input_smiles = smiles_dataset["smiles"]
    output_data = df[last_column]

    fingerprints = []

    # loop will go through each SMILE string in the clean dataset and convert them to MORGAN fingerprints
    # fingerprints are an object of rdkit so they need to be converted into a list object and then added to a fingerprint list
    fingerprint_size = int(input("What is the length of the fingerprints? "))
    for smile in input_smiles:
        mol = Chem.MolFromSmiles(smile) 
        if mol is not None:
        # Generate the Morgan fingerprint for the molecule
            radius = 2
            fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, radius, fingerprint_size)
            fingerprints.append(fingerprint)

        else:
            print("Failed to load the molecule from SMILES.")
 
    fingerprint_arrays = [list(fp) for fp in fingerprints]
    df = pd.DataFrame(fingerprint_arrays)
 
    X_data = df
    y_data = output_data
    return X_data, y_data

##################################################################################################################
#Used if option 3 is chosen to clean amino acid sequences
def remove_numbers(sequence, unwanted_amino_acids):
    """
    Parameters
    ----------
    sequence: input the amino acid string to be processed
    unwanted_amino_acids: input the list of characters (as strings) that should be removed from the amino acid string

    Returns
    -------
    cleaned_sequence: returns an amino acid string without characters found in the unwanted_amino_acid list
    """

    cleaned_sequence = ''.join([aa for aa in sequence if aa not in unwanted_amino_acids])
    return cleaned_sequence
##################################################################################################################
# Used if Option 3 is chosen to convert amino acids to one-hot vectors
def one_hot_encode(amino_acid_sequence):
    """
    Parameters
    ----------
    amino_acid_sequence: This function takes one amino acid sequence input at a time and returns the 
    compatible one_hot_encoded sequence

    Returns
    -------
    merged_one_hot_encoded_sequence: this function returns not a list of separate one_hot_encoded lists,
    but a merged list with a completely one_hot_encoded amino acid sequence

    """
    # Define a list of unique amino acids
    unique_amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']
    
    # Create a dictionary to map amino acids to indices
    amino_acid_to_index = {amino_acid: index for index, amino_acid in enumerate(unique_amino_acids)}
    
    one_hot_encoded_sequence = []
    unwanted_amino_acids = ['1', '2', '3', '4']
    cleaned_sequence = remove_numbers(amino_acid_sequence, unwanted_amino_acids)
    
    for amino_acid in cleaned_sequence:
        # Create a binary vector with all zeros
        one_hot_vector = [0] * len(unique_amino_acids)
        
        # Set the corresponding index to 1mod.
        one_hot_vector[amino_acid_to_index[amino_acid]] = 1
        
        # Append the one-hot vector to the final sequence
        one_hot_encoded_sequence.append(one_hot_vector)
        merged_one_hot_encoded_sequence = [item for sublist in one_hot_encoded_sequence for item in sublist]
    return merged_one_hot_encoded_sequence
##################################################################################################################
#Used if "y" or "yes" submitted to the graph_option user input

def graph_results(y_test, y_pred, graph_title, graph_color):
    """
    Parameters
    ----------
    y_test: input the y_test data from each specific regression model this function is used for
    y_pred: input the y_pred (predicted data from the model)
    graph_title: input the type of regression model to customize the graph's title

    Returns
    -------
    None.

    """
    if graph_option.strip() in ["y", "yes", "Y", "yeah", "si"]:
        plt.figure(dpi=1000)
        plt.plot(y_test,y_pred,'o',alpha=0.4, color = graph_color) # plot the prediction
        plt.xlabel('True Y Value', fontsize=12)
        plt.ylabel('Predicted Y Value', fontsize=12)
        plt.title(f'{graph_title} Regression Model', fontsize=14)
        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], "k--")
        plt.show()
    else:
        print("User chose for graphs not to be produced.")

def main():
    """
    Directs the code to which functions to use depending on user input.
    Calls all four regression models, calls the calculate_stats function to return the R2, MSE, MAE, and R Pearson values.
    Prints a final dataframe with a compilation of stats from all four models.
    Prints the times when the program begins and ends.

    Returns
    -------
    None.

    """
    # determine which path the code should follow depending on the user input given
    if data_type == "1":
        data_set = input("Input the name of the csv or txt file you would like to use: ")
        if ".txt" in data_set:
            output_file = data_set.replace("txt", "csv")
            txt_to_csv(data_set, output_file)
            changed_data_set = pd.read_csv(output_file, sep = ",")
        else:
            changed_data_set = data_set
        last_column = input("Input the name of the column with the expected/final data as it appears in the spreadsheet: ")
        df = pd.read_csv(data_set, delimiter=',')

        #define the x value (input properties) and true y outputs
        X_data = df.drop(last_column, axis = 1)
        y_data = df[last_column]
            
    elif data_type == "2":
        data_set = input("Input the name of the csv or txt file you would like to use: ")
        if ".txt" in data_set:
            output_file = data_set.replace("txt", "csv")
            txt_to_csv(data_set, output_file)
            changed_data_set = pd.read_csv(output_file, sep = ",")
        else:
            changed_data_set = data_set
        #Last column will be separated as "y", because this is the data the models will predict
        last_column = input("Input the name of the column with the expected/final data as it appears in the spreadsheet: ")
        df = pd.read_csv(changed_data_set, delimiter=',')
    
        #define the x value (input properties) and true y outputs
        X_data, y_data = smiles_to_fingerprints(changed_data_set, last_column)
    
    elif data_type == "3":
        data_set = input("Input the name of the csv or txt file you would like to use: ")
        print("")
        last_column = input("Input the name of the column with the expected/final data as it appears in the spreadsheet: ")
        print("")
        column_name = input("Input the name of the column with the amino acid sequences as it appears in the spreadsheet: ")
        
        #convert the input txt file to a csv file
        output_file = data_set.replace("txt", "csv")
        txt_to_csv(data_set, output_file)
        data = pd.read_csv(output_file, sep=",")
        
        #separates the columns to prepare the amino acids to be translated to one_hot_encoded sequences
        X = data.drop(last_column, axis = 1)
        y = data[last_column]
        
        #empty list to collect all of the one_hot_encoded sequences
        data = []
        for value in X[column_name]:
            #loop through all of the amino acid sequences in the dataframe column
            amino_acid_sequence = value
            one_hot_encoded_sequence = one_hot_encode(amino_acid_sequence)
            #add the one_hot_encoded list to the data list
            data.append(one_hot_encoded_sequence)
        
        # Convert sublists to strings and create a DataFrame
        df = pd.DataFrame(data)
        # Replace NaN values with a unique category (e.g., 'Missing')
        df.fillna('0', inplace=True)
        
        #separate the two columns and use for the rest of the program
        X_data = df
        y_data = y

    else:
        sys.exit("No valid data type provided.")
        
    current_time = datetime.datetime.now()
    formatted_time = current_time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"This program was started at {formatted_time}")
    
    #Call all four regression models and gather the statistics from them
    stats = linear_regression(X_data, y_data)
    
    stats1 = gaussian_regression(X_data, y_data)

    stats2 = decision_tree_regression(X_data, y_data)
    
    stats3 = random_forest_regression(X_data, y_data)

    #Make a list with all of the data collected by these models
    final_stats = [stats, stats1, stats2, stats3]

    #Create a dataframe of all of the data collected
    stats_df = pd.DataFrame(final_stats)

    #Change default row/column names in the dataframe
    index = stats_df.index
    columns = stats_df.columns
    index_list = index.tolist()
    column_list = columns.tolist()

    #Label the rows as the corresponding regression function
    index_list[0] = "Linear Regression"
    index_list[1] = "Gaussian Regression"
    index_list[2] = "Decision Tree Regression"
    index_list[3] = "Random Forest Regression"
    #Label the columns as the corresponding statistic
    column_list[0] = "R2 Value"
    column_list[1] = "MSE Value"
    column_list[2] = "MAE Value"
    column_list[3] = "R Pearson Value"

    #add these names to the final data frame
    stats_df.index = index_list
    stats_df.columns = column_list

    #print the final results of the Regression Module!!
    print(stats_df)
    current_time = datetime.datetime.now()
    formatted_time = current_time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"This program concluded at {formatted_time}")

##################################################################################################

def calculate_stats(y_test, y_pred):
    """
    Function to calculate general statistics that can be applied to each specific model
    Notes: R2, MSE, and MAE calculated through sklearn module
    R Pearson correlation coefficient calculated through NumPy module

    Parameters
    ----------
    y_test: The variable that is the true value of y in the dataset
    y_pred: The variable that the regression model predicted as the value of y in the data set

    Returns
    -------
    stats: list of R2, MSE, MAE, and R Pearson correlation coefficient values for each specific regression model the function is used for

    """
    r2 = r2_score(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    pearson = np.corrcoef(y_test, y_pred)[0, 1]
    stats = [r2, mse, mae, pearson]
    return stats

##################################################################################################
#Linear Regression Model

#train/test split is consistently 80/20 throughout this code
#random state values are set to 42 unless optimized using GridSearchCV
def linear_regression(X, y):
    """
    Implements a Linear Regression Model on the inputted data.    
    Parameters
    ----------
    X: input the X data, whether it be a molecular fingerprint, SMILES string, or amino acid string.
    y: input the y data, or the expected data values

    Returns
    -------
    list of statistics specific to this data module that is generated by the calculate_stats function.
    """

    start_time = time.time()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
    
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    graph_results(y_test, y_pred, "Linear", "#c91a46")
    
    end_time = time.time()
    total_time = end_time - start_time
    total_minutes = round((total_time/60), 3)
    print(f"Linear model took {total_minutes} minutes to run.")
    
    #Calculate Statistics 
    return calculate_stats(y_test, y_pred)
    
##################################################################################################
#Gaussian Process Regression Model (Optimized)

def gaussian_regression(X, y):
    """"
    Implements a Gaussian Process Regression Model on the inputted data.
    Parameters
    ----------
    X: input the X data, whether it be a molecular fingerprint, SMILES string, or amino acid string.
    y: input the y data, or the expected data values

    Returns
    -------
    list of statistics specific to this data module that is generated by the calculate_stats function.
    """
    start_time = time.time()
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
    
    #Find the parameters that optimize the Gaussian Model using sklearn's GridSearchCV function
    param_grid = {"alpha": [1e-3,1e-2,1e-1,1]}
    gp = GaussianProcessRegressor()
    grid_search = GridSearchCV(gp, param_grid=param_grid,cv=3)
    
    #Fit model using the training data
    grid_search.fit(X_train, y_train)
    
    #Return a dictionary of the optimal parameter values
    param_dict = grid_search.best_estimator_.get_params()
    alpha_param = param_dict["alpha"]
    kernel = RBF(length_scale = 1.0) 
    
    #Create a final optimized Gaussian Process model based on the GridSearchCV results
    gp = GaussianProcessRegressor(kernel = kernel, alpha=alpha_param, normalize_y=True, random_state=42)
    gp.fit(X_train, y_train)  
    #predict Lipophilicity values with the test data set to assess Gaussian Model
    y_pred, std = gp.predict(X_test, return_std = True) 
    
    graph_results(y_test, y_pred, "Gaussian Process", "#32a852")
    
    end_time = time.time()
    total_time = end_time - start_time
    total_minutes = round((total_time/60), 3)
    print(f"Gaussian model took {total_minutes} minutes to run.")
    
    #Calculate Gaussian Statistics
    return calculate_stats(y_test, y_pred)
#################################################################################################
#Decision Tree Model (Optimized)

def decision_tree_regression(X, y):
    """
    Implements a Decision Tree Regression Model on the inputted data.
    
    Parameters
    ----------
    X: input the X data, whether it be a molecular fingerprint, SMILES string, or amino acid string.
    y: input the y data, or the expected data values

    Returns
    -------
    list of statistics specific to this data module that is generated by the calculate_stats function.
    """
    
    start_time = time.time()
    
    #Split the data into a training set and a test set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)
    
    #Find the parameters that optimize the Decision Tree Model using sklearn's GridSearchCV function
    alphas = np.array([ 1e-7, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10]) 
    depths = np.array([5, 10, 20, 30, 40, 50, 100])   
    min_sample_leaf=np.array([5, 10, 15, 20, 30, 50]) 
    
    #Create a dictionary of all the possible parameter combinations, as specified above
    parameter_ranges = {'ccp_alpha':alphas, 'max_depth':depths, 'min_samples_leaf': min_sample_leaf} 
    
    tree1 = DecisionTreeRegressor()
    tree1_search = GridSearchCV(tree1, parameter_ranges,cv=3) 
    tree1_search.fit(X_train,y_train)
    
    #Using the optimized model, predict values from the X_test set
    y_pred=tree1_search.best_estimator_.predict(X_test)
    
    graph_results(y_test, y_pred, "Decision Tree", "#fc9403")
    
    end_time = time.time()
    total_time = end_time - start_time
    total_minutes = round((total_time/60), 3)
    print(f"Decision Tree model took {total_minutes} minutes to run.")
    
    #Calculate Decision Tree Stats
    return calculate_stats(y_test, y_pred)
#################################################################################################
#Random Forest Regression Model (Optimized)

def random_forest_regression(X, y):
    """"
    Implements a Random Forest Regression Model on the inputted data.
    
    Parameters
    ----------
    X: input the X data, whether it be a molecular fingerprint, SMILES string, or amino acid string.
    y: input the y data, or the expected data values

    Returns
    -------
    list of statistics specific to this data module that is generated by the calculate_stats function.
    """

    start_time = time.time()
    
    #Split the data into a training set and a test set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)
    
    #Outline the parameters that will be optimized
    paramater_ranges = {"ccp_alpha": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]}
    
    #Use sklearn's GridSearchCV function to find optimal parameters
    forest = RandomForestRegressor()
    forest_search = GridSearchCV(forest, paramater_ranges, cv=3) 
    forest_search.fit(X_train, y_train)
    
    #Create a dictionary of all of the optimal parameters for the Random Forest Model
    param_dict = forest_search.best_estimator_.get_params()
    
    #Specify each parameter that will be used in the final Random Forest Model from the param_dict
    ccp_alpha_param = param_dict["ccp_alpha"]
    
    #Code the final Random Forest model with the optimized parameters from the GridSearchCV function
    forest = RandomForestRegressor(n_estimators = 500, min_samples_leaf = 1, random_state = 5, ccp_alpha = ccp_alpha_param)
    forest.fit(X_train, y_train)
    
    #Predict test set data with optimized parameters
    y_pred = forest.predict(X_test) 
    
    graph_results(y_test, y_pred, "Random Forest", "#4287f5")
    
    end_time = time.time()
    total_time = end_time - start_time
    total_minutes = round((total_time/60), 3)
    print(f"Random Forest model took {total_minutes} minutes to run.")
    
    #Calculate Random Forest Stats
    return calculate_stats(y_test, y_pred)
#################################################################################################
#Conclude the program and call the main function
if __name__ == "__main__":
    main()
